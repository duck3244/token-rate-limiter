graph TB
    %% Input/Output
    subgraph "External Interface"
        API[ğŸŒ REST API<br/>Port 8080]
        Monitor[ğŸ“Š Monitoring<br/>/actuator/*]
    end
    
    %% Core Components
    subgraph "Core Components"
        Controller[ğŸ® LlamaController<br/>chat/completions<br/>models<br/>health<br/>usage]
        
        TokenLimit[ğŸ›¡ï¸ TokenLimitService<br/>checkTokenLimit<br/>recordTokenUsage<br/>getCurrentUsage]
        
        Proxy[ğŸ”„ LlamaProxyService<br/>proxyToLlama<br/>checkHealth<br/>getAvailableModels]
    end
    
    %% Configuration
    subgraph "Configuration"
        Config[âš™ï¸ TokenLimitConfig<br/>Max tokens settings<br/>vLLM URL config]
        
        RedisConfig[ğŸ”§ RedisConfig<br/>Connection settings<br/>Template setup]
        
        WebConfig[ğŸŒ WebConfig<br/>WebClient builder<br/>HTTP settings]
    end
    
    %% External Dependencies
    subgraph "External Systems"
        Redis[(ğŸ’¾ Redis<br/>Token counters<br/>Usage tracking<br/>TTL management)]
        
        vLLM[ğŸ¤– vLLM Server<br/>Llama 3.2 1B<br/>Chat completions<br/>Token counting]
    end
    
    %% Exception Handling
    subgraph "Error Handling"
        ExHandler[âš ï¸ GlobalExceptionHandler<br/>Rate limit errors<br/>Service errors<br/>Generic errors]
        
        Exceptions[ğŸ“‹ Exception Classes<br/>TokenLimitExceededException<br/>ModelServiceException]
    end
    
    %% Background Tasks
    subgraph "Background Tasks"
        Scheduler[â° ScheduledTasks<br/>Cleanup expired keys<br/>Health checks<br/>Daily stats]
    end
    
    %% Connections
    API --> Controller
    Monitor --> Controller
    
    Controller --> TokenLimit
    Controller --> Proxy
    Controller --> ExHandler
    
    Proxy --> TokenLimit
    Proxy --> vLLM
    
    TokenLimit --> Redis
    TokenLimit --> Config
    
    Proxy --> Config
    Controller --> WebConfig
    TokenLimit --> RedisConfig
    
    ExHandler --> Exceptions
    Scheduler --> Redis